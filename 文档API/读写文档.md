## 读，写文档（Reading and Writing documents）

### 简介

Elasticsearch中的每个索引都被[divided into shards](https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html#getting-started-shards-and-replicas) ，每个碎片可以有多个副本。这些副本被称为replication group，并且在添加或删除文档时必须保持同步。如果我们不这样做，从一个副本读取将导致非常不同的结果比另一个读取。保持分片副本同步并从中读取*数据的*过程就是我们所说数据复制模型。

Elasticsearch的数据复制模型基于*主备份模型*，在微软研究院的[PacificA论文](https://www.microsoft.com/en-us/research/publication/pacifica-replication-in-log-based-distributed-storage-systems/)中有很好的描述 。该模型基于具有充当主分片的复制组的单个副本。其他副本称为*副本碎片*。主要作为所有索引操作的主要入口点。它负责验证它们并确保它们是正确的。一旦主服务器接受了索引操作，主服务器也负责将操作复制到其他副本。

本节的目的是对Elasticsearch复制模型进行高度概述，并讨论其对写入和读取操作之间各种交互的影响。

### 基本的写模型

Elasticsearch中的每个索引操作首先使用[路由](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html#index-routing)（通常基于文档ID）解析为复制组。一旦确定了复制组，操作就会在内部转发到组的当前*主分片*。主分片（primary shard）负责验证操作并将其转发给其他副本。由于副本可以脱机，因此主服务器不需要复制到所有副本。相反，Elasticsearch维护应接收操作的分片副本列表。该列表被称为*同步副本*并由主节点维护。顾名思义，这是一组“好”的分片副本，保证已经处理了所有已经被确认给用户的索引和删除操作。主要负责维护这个不变量，因此必须将所有操作复制到这个集合中的每个副本。

primary shard遵循这个基本流程：

1. 验证传入的操作，并在结构无效的情况下拒绝它（例如：有一个对象字段，其中数字是预期的）
2. 在本地执行操作即索引或删除相关文档。这也将验证字段的内容，并在需要时拒绝（例如：在Lucene中索引的关键字值太长）。
3. 将操作转发到当前同步副本集中的每个副本。如果有多个副本，这是并行完成的。
4. 一旦所有副本都成功执行操作并响应主要操作，主要确认成功完成对客户端的请求。

#### 失败处理

索引期间很多事情可能会出错 - 磁盘可能损坏，节点可能互相断开连接，或者某些配置错误可能导致副本上的操作失败，尽管在主节点上成功。这种情况很少发生，但主要还是要对它们作出回应。

在主服务器本身发生故障的情况下，托管主服务器的节点将向主服务器发送关于它的消息。索引操作将等待（[默认情况下](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html#dynamic-index-settings)最多1分钟），以便主服务器将其中一个副本提升为新的主服务器。该操作将被转发到新的主要进行处理。请注意，主站还监视节点的健康状况，并可能决定主动降级主站。当通过网络问题将持有主节点的节点与群集隔离时，通常会发生这种情况。[在这里](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#demoted-primary)看到更多的细节。

在主服务器上成功执行操作后，主服务器在副本碎片上执行操作时必须处理潜在的故障。这可能是由副本上的实际故障或由于网络问题导致操作无法到达副本（或阻止副本响应）所致。所有这些共享相同的最终结果：作为同步副本集的一部分的副本未命中即将被确认的操作。为了避免违反不变量，主要发送一条消息给主机，请求将有问题的分片从同步副本集中移除。只有主人确认删除碎片后，主要确认操作。

在将操作转发到副本时，主服务器将使用副本来验证它仍然是活动的主服务器。如果主节点由于网络分区（或长GC）而被隔离，则可能会继续处理传入索引操作，然后才意识到已将其降级。从陈旧的主要来的操作将被复制品拒绝。当主服务器收到拒绝请求的副本的响应，因为它不再是主服务器，那么它将与主服务器联系，并且将知道它已被替换。操作然后被路由到新的主要。

**如果没有副本会发生什么？**

这是由于索引配置或仅因为所有副本都失败而可能发生的有效方案。在这种情况下，主要是处理操作，没有任何外部验证，这可能看起来有问题。另一方面，primary不能自行破坏其他的碎片，而是要求master代表它。这意味着master知道primary是唯一的一个好的副本。因此，我们保证，master不会将任何其他（过时的）分片副本推广为新的主分区，并且索引到主分区的任何操作都不会丢失。当然，从那时起，我们只运行单个数据副本，物理硬件问题可能会导致数据丢失。请参阅[等待活动碎片](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html#index-wait-for-active-shards)[编辑](https://github.com/elastic/elasticsearch/edit/6.1/docs/reference/docs/index_.asciidoc)一些缓解选项。

### 基本读模型

在Elasticsearch中读取可以通过ID进行非常轻量级的查找，也可以通过使用复杂聚合的沉重搜索请求来实现，而这些请求将占用大量的CPU资源。主备份模式的一个优点是它保持所有碎片副本一致（除in-flight操作外）。因此，单个同步副本足以满足读取请求。

当一个节点接收到读请求时，该节点负责将其转发到保存相关分片的节点，整理响应并响应客户端。我们称该节点为该请求的*协调节点*。基本流程如下：

1. 将读取请求解析到相关的分片。请注意，由于大多数搜索将被发送到一个或多个索引，它们通常需要从多个分片读取，每个分片代表不同的数据子集。
2. 从分片复制组中选择每个相关分片的活动副本。这可以是主要的或副本。默认情况下，Elasticsearch只是在分片之间循环。
3. 发送shard level读取请求到选定的副本。
4. 结合结果并作出回应。请注意，在通过ID查找的情况下，只有一个分片是相关的，并且这个步骤可以被跳过。

#### 失败处理

当分片无法响应读取请求时，协调节点将从同一个复制组中选择另一个副本，并将碎片级别搜索请求发送到该副本。重复性故障可能导致没有分片副本可用。在某些情况下，比如`_search`Elasticsearch会倾向于快速响应，尽管有部分结果，而不是等待问题得到解决（部分结果`_shards`在响应标题中指出）。

### 几个简单的含义

这些基本流程中的每一个都决定了Elasticsearch如何作为读写系统。而且，由于读取和写入请求可以同时执行，这两个基本流程相互交互。这有一些内在的含义：

- 有效的读取

  在正常操作下，每个相关复制组执行一次读取操作。只有在失败情况下，同一个分片的多个副本才能执行相同的搜索。

- 阅读未确认

  由于主要首先在本地建立索引，然后复制请求，所以并发读取可能在确认之前就已经看到了更改。

- 默认两份

  这个模型可以是容错的，同时只保留两个数据副本。这与基于法定人数的系统相反，其中容错的最小副本数为3。

### 失败

在失败的情况下，以下是可能的：

- 一个分片会减慢索引

  由于primary在每个操作期间等待在同步副本中设置的所有副本，因此一个慢分片可能会减慢整个replication group的速度。这是我们为上述读取效率付出的代价。当然，单个缓慢的分片也会减慢已经发送给它的不幸的搜索。

- 脏读

  一个孤立的primary可以暴露不会被确认的写入。这是由于一个孤立的主服务器只有在向副本发送请求或向主服务器发送请求时才会被隔离。此时操作已经被索引到主数据库中，并可以通过并行读取来读取。Elasticsearch通过每秒（在默认情况下）对主服务器进行ping操作，并在没有主服务器的情况下拒绝索引操作来减轻这种风险。

### 关于未知大坑的提示（Iceberg）

本文档提供了Elasticsearch如何处理数据的高级概述。当然，还有很多事情要做。诸如主要术语，集群状态发布和主选举之类的事情都起着保持这个系统正常运转的作用。这个文件也不包括已知和重要的错误（包括关闭和打开）。我们认识到[GitHub很难跟上](https://github.com/elastic/elasticsearch/issues?q=label%3Aresiliency)。为了帮助人们保持最佳状态，我们 在我们的网站上维护一个专门的[resiliency page](https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html)。我们强烈建议阅读一下。